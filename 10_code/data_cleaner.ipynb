{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we'll make a clean dataframe with years as the index from 1950 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">1950</th>\n",
       "      <th>1</th>\n",
       "      <td>1950-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1950-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1950-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1950-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1950-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1950-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1950-10-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date\n",
       "year month           \n",
       "1950 1     1950-01-01\n",
       "     2     1950-02-01\n",
       "     3     1950-03-01\n",
       "     4     1950-04-01\n",
       "     5     1950-05-01\n",
       "     6     1950-06-01\n",
       "     7     1950-07-01\n",
       "     8     1950-08-01\n",
       "     9     1950-09-01\n",
       "     10    1950-10-01"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the empty dataframe with years and months from 1950 to 2022 as the index\n",
    "df = pd.DataFrame(index=pd.MultiIndex.from_product([range(1950, 2023), range(1, 13)], names=['year', 'month']))\n",
    "# add a year_month column\n",
    "df['date'] = df.index.to_series().apply(lambda x: str(x[0]) + '-' + str(x[1]).zfill(2))\n",
    "# convert the year_month column to a datetime object\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we'll need to configure the US census data by taking the overall US population and smoothing for missing years in between census reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151325798</td>\n",
       "      <td>1950-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>179323175</td>\n",
       "      <td>1960-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>203211926</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>226545805</td>\n",
       "      <td>1980-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>248709873</td>\n",
       "      <td>1990-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>281421906</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>308745538</td>\n",
       "      <td>2010-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>331449281</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Population       date\n",
       "4    151325798 1950-01-01\n",
       "5    179323175 1960-01-01\n",
       "6    203211926 1970-01-01\n",
       "7    226545805 1980-01-01\n",
       "8    248709873 1990-01-01\n",
       "9    281421906 2000-01-01\n",
       "10   308745538 2010-01-01\n",
       "11   331449281 2020-01-01"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ingest the census data\n",
    "census_df = pd.read_excel(\n",
    "    \"../00_source_data/population-change-data-table.xlsx\", skiprows=3\n",
    ")\n",
    "# keep only census columns\n",
    "census_df = census_df[\n",
    "    [\n",
    "        \"Area\",\n",
    "        \"1910 Census\",\n",
    "        \"1920 Census\",\n",
    "        \"1930 Census\",\n",
    "        \"1940 Census\",\n",
    "        \"1950 Census\",\n",
    "        \"1960 Census\",\n",
    "        \"1970 Census\",\n",
    "        \"1980 Census\",\n",
    "        \"1990 Census\",\n",
    "        \"2000 Census\",\n",
    "        \"2010 Census\",\n",
    "        \"2020 Census\",\n",
    "    ]\n",
    "]\n",
    "# rename the mispelled United States1 to US\n",
    "census_df.loc[census_df[\"Area\"] == \"United States1\", \"Area\"] = \"US\"\n",
    "# Pull out only the US row\n",
    "census_df = census_df[census_df[\"Area\"] == \"US\"]\n",
    "# pivot the census data\n",
    "census_df = census_df.melt(id_vars=[\"Area\"], var_name=\"Year\", value_name=\"Population\")\n",
    "# convert the year column to a datetime\n",
    "census_df[\"date\"] = pd.to_datetime(census_df[\"Year\"], format=\"%Y Census\")\n",
    "# drop the Area column\n",
    "census_df = census_df.drop(columns=[\"Area\", \"Year\"])\n",
    "# convert the population column to an integer\n",
    "census_df[\"Population\"] = census_df[\"Population\"].astype(int)\n",
    "# filter for just the years after 1949\n",
    "census_df = census_df[census_df[\"date\"] > \"1949-12-31\"]\n",
    "\n",
    "census_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will pull in energy production data from government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy_Prod</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979-08-01</th>\n",
       "      <td>16.723152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-01</th>\n",
       "      <td>16.804429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-01</th>\n",
       "      <td>17.891468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-08-01</th>\n",
       "      <td>15.010994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-06-01</th>\n",
       "      <td>15.975444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982-09-01</th>\n",
       "      <td>15.704539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>21.936461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-01</th>\n",
       "      <td>17.441746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01</th>\n",
       "      <td>18.166537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-07-01</th>\n",
       "      <td>17.029478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Energy_Prod\n",
       "date                   \n",
       "1979-08-01    16.723152\n",
       "2000-12-01    16.804429\n",
       "2001-03-01    17.891468\n",
       "1975-08-01    15.010994\n",
       "1981-06-01    15.975444\n",
       "1982-09-01    15.704539\n",
       "2017-11-01    21.936461\n",
       "2007-03-01    17.441746\n",
       "1996-08-01    18.166537\n",
       "1984-07-01    17.029478"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_df = pd.read_csv(\"../00_source_data/MER_T01_02.csv\")\n",
    "# split the YYYYMM column into year and month\n",
    "energy_df[\"year\"] = energy_df[\"YYYYMM\"].apply(lambda x: int(str(x)[:4]))\n",
    "energy_df[\"month\"] = energy_df[\"YYYYMM\"].apply(lambda x: int(str(x)[4:]))\n",
    "# if the month column is 13 make it 1\n",
    "energy_df.loc[energy_df[\"month\"] == 13, \"month\"] = 1\n",
    "# make a date column from year and month columns and add the day as 01\n",
    "energy_df[\"date\"] = pd.to_datetime(\n",
    "    energy_df[\"year\"].astype(str) + \"-\" + energy_df[\"month\"].astype(str) + \"-01\"\n",
    ")\n",
    "# keep the Value and Year columns\n",
    "energy_df = energy_df[[\"Value\", \"date\"]]\n",
    "# Rename the value column to energy_prod\n",
    "energy_df = energy_df.rename(columns={\"Value\": \"Energy_Prod\"})\n",
    "# drop the rows with Not Available\n",
    "energy_df = energy_df[energy_df[\"Energy_Prod\"] != \"Not Available\"]\n",
    "# convert Energy_Prod to a float\n",
    "energy_df[\"Energy_Prod\"] = energy_df[\"Energy_Prod\"].astype(float)\n",
    "# groupby year and sum the energy\n",
    "energy_df = energy_df.groupby(\"date\").sum()\n",
    "\n",
    "energy_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next is energy consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy_Consume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-11-01</th>\n",
       "      <td>22.887871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-01</th>\n",
       "      <td>24.518026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-01</th>\n",
       "      <td>22.278099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-01-01</th>\n",
       "      <td>246.388390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-01</th>\n",
       "      <td>25.648101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-06-01</th>\n",
       "      <td>19.778763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-11-01</th>\n",
       "      <td>22.692209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>306.936908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-09-01</th>\n",
       "      <td>16.888119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-01</th>\n",
       "      <td>22.461487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Energy_Consume\n",
       "date                      \n",
       "2003-11-01       22.887871\n",
       "2003-03-01       24.518026\n",
       "2016-10-01       22.278099\n",
       "1985-01-01      246.388390\n",
       "2007-08-01       25.648101\n",
       "1990-06-01       19.778763\n",
       "1997-11-01       22.692209\n",
       "2001-01-01      306.936908\n",
       "1985-09-01       16.888119\n",
       "2012-06-01       22.461487"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consume_df = pd.read_csv(\"../00_source_data/MER_T01_03.csv\")\n",
    "# split the YYYYMM column into year and month\n",
    "consume_df[\"year\"] = consume_df[\"YYYYMM\"].apply(lambda x: int(str(x)[:4]))\n",
    "consume_df[\"month\"] = consume_df[\"YYYYMM\"].apply(lambda x: int(str(x)[4:]))\n",
    "# if the month column is 13 make it 1\n",
    "consume_df.loc[consume_df[\"month\"] == 13, \"month\"] = 1\n",
    "# make a date column from year and month columns and add the day as 01\n",
    "consume_df[\"date\"] = pd.to_datetime(\n",
    "    consume_df[\"year\"].astype(str) + \"-\" + consume_df[\"month\"].astype(str) + \"-01\"\n",
    ")\n",
    "# keep the Value and Year columns\n",
    "consume_df = consume_df[[\"Value\", \"date\"]]\n",
    "# Rename the value column to energy_prod\n",
    "consume_df = consume_df.rename(columns={\"Value\": \"Energy_Consume\"})\n",
    "# drop the rows with Not Available\n",
    "consume_df = consume_df[consume_df[\"Energy_Consume\"] != \"Not Available\"]\n",
    "# convert Energy_Prod to a float\n",
    "consume_df[\"Energy_Consume\"] = consume_df[\"Energy_Consume\"].astype(float)\n",
    "# groupby year and sum the energy\n",
    "consume_df = consume_df.groupby(\"date\").sum()\n",
    "\n",
    "consume_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we have the vehicle efficiency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Veh_MPG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955-01-01</th>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-01</th>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974-01-01</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>18.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969-01-01</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-01</th>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966-01-01</th>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954-01-01</th>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Veh_MPG\n",
       "date               \n",
       "2001-01-01     17.1\n",
       "1955-01-01     12.7\n",
       "2002-01-01     16.9\n",
       "1974-01-01     12.0\n",
       "2017-01-01     18.1\n",
       "1969-01-01     12.0\n",
       "1999-01-01     16.7\n",
       "1990-01-01     16.4\n",
       "1966-01-01     12.4\n",
       "1954-01-01     12.7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veh_df = pd.read_csv(\"../00_source_data/MER_T01_08.csv\")\n",
    "# subset for the rows where unit is Miles per Gallon\n",
    "veh_df = veh_df[veh_df[\"Unit\"] == \"Miles per Gallon\"]\n",
    "# keep Descriptions where the value is All Motor Vehicles Fuel Economy\n",
    "veh_df = veh_df[veh_df[\"Description\"] == \"All Motor Vehicles Fuel Economy\"]\n",
    "# split the YYYYMM column into two columns\n",
    "veh_df[\"Year\"] = veh_df[\"YYYYMM\"].astype(str).str[:4]\n",
    "veh_df[\"Month\"] = veh_df[\"YYYYMM\"].astype(str).str[4:]\n",
    "# # if the month column is 13 make it 1\n",
    "veh_df.loc[veh_df[\"Month\"] == \"13\", \"Month\"] = \"1\"\n",
    "# # make a date column from year and month columns and add the day as 01\n",
    "veh_df[\"date\"] = pd.to_datetime(\n",
    "    veh_df[\"Year\"].astype(str) + \"-\" + veh_df[\"Month\"].astype(str) + \"-01\"\n",
    ")\n",
    "# keep the Value and Year columns\n",
    "veh_df = veh_df[[\"Value\", \"date\"]]\n",
    "# # Rename the value column to Veh_MPG\n",
    "veh_df = veh_df.rename(columns={\"Value\": \"Veh_MPG\"})\n",
    "# # convert Veh_MPG to a float\n",
    "veh_df[\"Veh_MPG\"] = veh_df[\"Veh_MPG\"].astype(float)\n",
    "# # groupby year and take the mean\n",
    "veh_df = veh_df.groupby(\"date\").mean()\n",
    "\n",
    "veh_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOAA Weather data is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a loop to read in all the csv files in the folder and merge them into one dataframe\n",
    "# create a list of the files in the folder\n",
    "files = os.listdir(\"../00_source_data/NOAA_data\")\n",
    "# create an empty list to hold the dataframes   \n",
    "dfs = []\n",
    "# loop through the files\n",
    "for file in files:\n",
    "    # read in the csv file\n",
    "    df = pd.read_csv(\"../00_source_data/NOAA_data/\" + file, skiprows=4)\n",
    "    # append the dataframe to the list\n",
    "    dfs.append(df)\n",
    "# merge the dataframes into one dataframe\n",
    "noaa_df = pd.concat(dfs)\n",
    "\n",
    "# convert the date column to a datetime object of month and year\n",
    "noaa_df[\"date\"] = pd.to_datetime(noaa_df[\"Date\"], format=\"%Y%m\")\n",
    "\n",
    "# rename Value to AvgTemp\n",
    "noaa_df = noaa_df.rename(columns={\"Value\": \"AvgTemp\"})\n",
    "\n",
    "# drop the date and anomaly columns\n",
    "noaa_df = noaa_df.drop(columns=[\"Date\", \"Anomaly\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgTemp</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>69.87</td>\n",
       "      <td>1996-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>50.63</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.10</td>\n",
       "      <td>1944-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>74.66</td>\n",
       "      <td>2003-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60.58</td>\n",
       "      <td>1952-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>52.32</td>\n",
       "      <td>1981-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>55.69</td>\n",
       "      <td>2017-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65.55</td>\n",
       "      <td>1969-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>56.68</td>\n",
       "      <td>2007-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>30.60</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AvgTemp       date\n",
       "56    69.87 1996-06-01\n",
       "82    50.63 2022-04-01\n",
       "4     72.10 1944-08-01\n",
       "63    74.66 2003-08-01\n",
       "12    60.58 1952-05-01\n",
       "41    52.32 1981-10-01\n",
       "77    55.69 2017-10-01\n",
       "29    65.55 1969-09-01\n",
       "67    56.68 2007-10-01\n",
       "81    30.60 2021-02-01"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaa_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we merge data starting with the census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# merge the census data with the empty dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(df, census_df, on\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m, how\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# smooth the population column\u001b[39;00m\n\u001b[1;32m      4\u001b[0m merged_df[\u001b[39m\"\u001b[39m\u001b[39mPopulation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m merged_df[\u001b[39m\"\u001b[39m\u001b[39mPopulation\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39minterpolate()\n",
      "File \u001b[0;32m~/Desktop/energy-predictions/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[1;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Desktop/energy-predictions/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[1;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/Desktop/energy-predictions/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1179\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m lk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     \u001b[39m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     \u001b[39m#  the latter of which will raise\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m     lk \u001b[39m=\u001b[39m cast(Hashable, lk)\n\u001b[0;32m-> 1179\u001b[0m     left_keys\u001b[39m.\u001b[39mappend(left\u001b[39m.\u001b[39;49m_get_label_or_level_values(lk))\n\u001b[1;32m   1180\u001b[0m     join_names\u001b[39m.\u001b[39mappend(lk)\n\u001b[1;32m   1181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     \u001b[39m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/energy-predictions/.venv/lib/python3.9/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "# merge the census data with the empty dataframe\n",
    "merged_df = pd.merge(df, census_df, on=\"date\", how=\"left\")\n",
    "# smooth the population column\n",
    "merged_df[\"Population\"] = merged_df[\"Population\"].interpolate()\n",
    "merged_df.plot(x=\"date\", y=\"Population\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we add energy production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the energy data with the merged dataframe\n",
    "merged_df2 = pd.merge(merged_df, energy_df, on=\"date\", how=\"left\").copy()\n",
    "# smooth the energy column\n",
    "merged_df2[\"Energy_Prod\"] = merged_df2[\"Energy_Prod\"].interpolate()\n",
    "merged_df2.plot(x=\"date\", y=\"Energy_Prod\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we add energy consumption data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with the consumption data\n",
    "merged_df3 = pd.merge(merged_df2, consume_df, on=\"date\", how=\"left\").copy()\n",
    "# smooth the consumption column\n",
    "merged_df3[\"Energy_Consume\"] = merged_df3[\"Energy_Consume\"].interpolate()\n",
    "merged_df3.plot(x=\"date\", y=\"Energy_Consume\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The last merge will be the vehicle efficiency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vehicle data\n",
    "merged_df4 = pd.merge(merged_df3, veh_df, on=\"date\", how=\"left\").copy()\n",
    "# smooth the vehicle column\n",
    "merged_df4[\"Veh_MPG\"] = merged_df4[\"Veh_MPG\"].interpolate()\n",
    "merged_df4.plot(x=\"date\", y=\"Veh_MPG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add NOAA average temp to the overall df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the NOAA df on date\n",
    "merged_df5 = pd.merge(merged_df4, noaa_df, on=\"date\", how=\"left\").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output File as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save merged df4 to a csv in the 20_clean_data_directory\n",
    "merged_df4.to_csv(\"../20_clean_data/merged_df4.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6348038c22bbb1f5066bdf2baff95f32efff54813dc5babbc7f04290435957a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
